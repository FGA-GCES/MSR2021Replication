so, electron, be the junction of node.j and chromium, in essenc support both blob and node.j buffer and fs api.now, in my preload js, i need to load in a number of file and pass them to the render context. however, i'v disabl nodeintegration, and these file need to be pass in as blobs. some of these blobs, though, might be sever gbs in size.now, i know i can read the file and build the blob progressively, with someth like,const fs = require('fs');async function loadasblob(path) { var blob = null; function expand(data) { if(blob === null) blob = new blob([data]); els blob = new blob([blob,data]); } var hdl = await fs.promises.open(path), buffers = 16 * 1024 * 1024, // 16mbs at a time buffer = new uint8array(buffersize), size = (await hdl.stat({bigint: true})).size, pos = 0n; while(po &lt; size) { let read = await hdl.read(buffer, 0, buffersize); pos += bigint(buffersize); if(po &gt; size) expand(buffer.subarray(0,read.bytesread)); els expand(buffer); } return blob;}but this is obvious ineffici sinc it copi the file as a whole into the blob object in memori (it took an estim 15 second to load a 1.9gb file), whereas, with the drag-and-drop file api, the file drop are instant load becaus the data isn't resolv immediately.so, final my question,how would i go about generat a blob for the applic via electron in a way that doesn't resolv (or copy) it, in the same manner that the drag-and-drop api does?
